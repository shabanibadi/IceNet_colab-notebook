{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkoPDXTcXNyM0ifmKVf8sD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shabanibadi/IceNet_colab-notebook/blob/main/IceNet_colab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnjxeEJZcn77",
        "outputId": "7c0419ae-f0b9-492a-cd68-98b9cd2a934a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IceNet'...\n",
            "remote: Enumerating objects: 2158, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 2158 (delta 60), reused 123 (delta 50), pack-reused 2022\u001b[K\n",
            "Receiving objects: 100% (2158/2158), 108.61 MiB | 15.52 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/keunsoo-ko/IceNet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd IceNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrhNIX8OcxY2",
        "outputId": "72a4c943-592c-4577-fc40-cf6dfa3cf8c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IceNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python model.py"
      ],
      "metadata": {
        "id": "tubYGXpRc3E7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python Myloss.py"
      ],
      "metadata": {
        "id": "wdISHcKSdBeK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python dataloader.py"
      ],
      "metadata": {
        "id": "DD_SNVO0xQk9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python Train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUd1MxHTdKIp",
        "outputId": "23d18049-df85-4d32-af1d-25c6d8606925"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training examples: 2002\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Train.py:60: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(IceNet.parameters(),config.grad_clip_norm)\n",
            "Epoch0, Loss at iteration10 : 0.6658169627189636\n",
            "Epoch0, Loss at iteration20 : 0.7529795169830322\n",
            "Epoch0, Loss at iteration30 : 0.5054782032966614\n",
            "Epoch0, Loss at iteration40 : 0.3700137734413147\n",
            "Epoch0, Loss at iteration50 : 0.3388810455799103\n",
            "Epoch0, Loss at iteration60 : 0.31578385829925537\n",
            "Epoch0, Loss at iteration70 : 0.3558133542537689\n",
            "Epoch0, Loss at iteration80 : 0.33035409450531006\n",
            "Epoch0, Loss at iteration90 : 0.3787999749183655\n",
            "Epoch0, Loss at iteration100 : 0.3176299035549164\n",
            "Epoch0, Loss at iteration110 : 0.4568609595298767\n",
            "Epoch0, Loss at iteration120 : 0.3634026348590851\n",
            "Epoch0, Loss at iteration130 : 0.33097314834594727\n",
            "Epoch0, Loss at iteration140 : 0.3137951195240021\n",
            "Epoch0, Loss at iteration150 : 0.32917922735214233\n",
            "Epoch0, Loss at iteration160 : 0.29098889231681824\n",
            "Epoch0, Loss at iteration170 : 0.3028290569782257\n",
            "Epoch0, Loss at iteration180 : 0.30796656012535095\n",
            "Epoch0, Loss at iteration190 : 0.34325090050697327\n",
            "Epoch0, Loss at iteration200 : 0.30502790212631226\n",
            "Epoch0, Loss at iteration210 : 0.3011636734008789\n",
            "Epoch0, Loss at iteration220 : 0.3085568845272064\n",
            "Epoch0, Loss at iteration230 : 0.32616543769836426\n",
            "Epoch0, Loss at iteration240 : 0.29877832531929016\n",
            "Epoch0, Loss at iteration250 : 0.30172666907310486\n",
            "Epoch1, Loss at iteration10 : 0.3391803205013275\n",
            "Epoch1, Loss at iteration20 : 0.31897738575935364\n",
            "Epoch1, Loss at iteration30 : 0.32579275965690613\n",
            "Epoch1, Loss at iteration40 : 0.30303898453712463\n",
            "Epoch1, Loss at iteration50 : 0.28693512082099915\n",
            "Epoch1, Loss at iteration60 : 0.288842111825943\n",
            "Epoch1, Loss at iteration70 : 0.3202541470527649\n",
            "Epoch1, Loss at iteration80 : 0.34418004751205444\n",
            "Epoch1, Loss at iteration90 : 0.3112640380859375\n",
            "Epoch1, Loss at iteration100 : 0.3127228319644928\n",
            "Epoch1, Loss at iteration110 : 0.33823898434638977\n",
            "Epoch1, Loss at iteration120 : 0.3112068474292755\n",
            "Epoch1, Loss at iteration130 : 0.30677667260169983\n",
            "Epoch1, Loss at iteration140 : 0.3176233172416687\n",
            "Epoch1, Loss at iteration150 : 0.3017103374004364\n",
            "Epoch1, Loss at iteration160 : 0.298999160528183\n",
            "Epoch1, Loss at iteration170 : 0.34482935070991516\n",
            "Epoch1, Loss at iteration180 : 0.2906109392642975\n",
            "Epoch1, Loss at iteration190 : 0.3116273880004883\n",
            "Epoch1, Loss at iteration200 : 0.3063185214996338\n",
            "Epoch1, Loss at iteration210 : 0.3178693950176239\n",
            "Epoch1, Loss at iteration220 : 0.29739174246788025\n",
            "Epoch1, Loss at iteration230 : 0.3204277753829956\n",
            "Epoch1, Loss at iteration240 : 0.33304455876350403\n",
            "Epoch1, Loss at iteration250 : 0.29438772797584534\n",
            "Epoch2, Loss at iteration10 : 0.2987482249736786\n",
            "Epoch2, Loss at iteration20 : 0.32358741760253906\n",
            "Epoch2, Loss at iteration30 : 0.35299262404441833\n",
            "Epoch2, Loss at iteration40 : 0.2933550179004669\n",
            "Epoch2, Loss at iteration50 : 0.283999502658844\n",
            "Epoch2, Loss at iteration60 : 0.3249061405658722\n",
            "Epoch2, Loss at iteration70 : 0.3191239833831787\n",
            "Epoch2, Loss at iteration80 : 0.302046000957489\n",
            "Epoch2, Loss at iteration90 : 0.28553909063339233\n",
            "Epoch2, Loss at iteration100 : 0.28748375177383423\n",
            "Epoch2, Loss at iteration110 : 0.2928387224674225\n",
            "Epoch2, Loss at iteration120 : 0.29866543412208557\n",
            "Epoch2, Loss at iteration130 : 0.3072540760040283\n",
            "Epoch2, Loss at iteration140 : 0.3237660825252533\n",
            "Epoch2, Loss at iteration150 : 0.30703654885292053\n",
            "Epoch2, Loss at iteration160 : 0.3181808888912201\n",
            "Epoch2, Loss at iteration170 : 0.28597885370254517\n",
            "Epoch2, Loss at iteration180 : 0.31172114610671997\n",
            "Epoch2, Loss at iteration190 : 0.2890246510505676\n",
            "Epoch2, Loss at iteration200 : 0.3027728796005249\n",
            "Epoch2, Loss at iteration210 : 0.2941130995750427\n",
            "Epoch2, Loss at iteration220 : 0.2838280200958252\n",
            "Epoch2, Loss at iteration230 : 0.3038317859172821\n",
            "Epoch2, Loss at iteration240 : 0.306911438703537\n",
            "Epoch2, Loss at iteration250 : 0.3127008080482483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python demo_video.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD_3CettzAaW",
        "outputId": "6494c76c-6648-4558-a5c1-e4af4f268105"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demo_video.py:68: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)\n",
            "  lowlight = torch.from_numpy(img).float()\n",
            "qt.qpa.xcb: could not connect to display \n",
            "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/usr/local/lib/python3.7/dist-packages/cv2/qt/plugins\" even though it was found.\n",
            "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
            "\n",
            "Available platform plugins are: xcb.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python demo_interactive.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tBynAAzza-I",
        "outputId": "2b161c90-f8e3-4755-b696-e41a37de286d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demo_interactive.py:62: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:172.)\n",
            "  lowlight = torch.from_numpy(img).float()\n",
            "qt.qpa.xcb: could not connect to display \n",
            "qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/usr/local/lib/python3.7/dist-packages/cv2/qt/plugins\" even though it was found.\n",
            "This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n",
            "\n",
            "Available platform plugins are: xcb.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}